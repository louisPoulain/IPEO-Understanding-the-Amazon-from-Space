{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a42d9e64",
   "metadata": {},
   "source": [
    "# Evaluation Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "735bb817",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "\n",
    "either provide a download link here: https://drive.google.com/drive/folders/1tOMxGHMRtY8E1p1NKun6Wi_4DHMmRjAq?usp=sharing  \n",
    "(sorry but gdown seemingly can't handle more than 50 files at a time and we have 40000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddc6294d",
   "metadata": {},
   "source": [
    "You need to keep the same structure as in the drive file to avoid any problem  \n",
    "i.e.: you should download the whole folder named IPEO_Planet_project and have the following structure  \n",
    " - submission_<names_our_names>  \n",
    "   - IPEO-Understanding-the-Amazon-from-Space  \n",
    "     - some code + logs + CSV  \n",
    "     - this file <evaluation.ipynb>\n",
    "   - IPEO_Planet_project\n",
    "     - checkpoints  \n",
    "     - train-jpg  \n",
    "     - train_labels.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e4cfb5",
   "metadata": {},
   "source": [
    "## Your Plots and Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4332d2d",
   "metadata": {},
   "source": [
    "By now you should have run the command to install to relevant packages in your virtual env (pip install -r requirements.txt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f197786",
   "metadata": {},
   "source": [
    "Please check that you have a gpu enabled, otherwise the loading of the checkpoint and the creation of the trainer may not work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3149902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DatasetAmazon\n",
    "from model import PlanetModel, testModel, ResNet\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import time\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from accuracy_metrics import Hamming_distance, transform_pred, overall_acc, count_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc55601",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) # check that "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8da7cb9",
   "metadata": {},
   "source": [
    "If you just want to see if it runs set:  \n",
    " - full, tiny = False, True  \n",
    "\n",
    "Note: you will **NOT** retrieve our results with this option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac0bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full, tiny = True, False\n",
    "test_dataset = DatasetAmazon(full=full, tiny=tiny, test=True, path_to_labels=\"CSV/train_label_vector.pkl\")\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size = 1, num_workers=4, shuffle=False) # change workers if you have more"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fe7834d",
   "metadata": {},
   "source": [
    "### Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ResNet18-epoch=47_over_50-val_accuracy=0.93.ckpt\"\n",
    "checkpoint_path = \"../IPEO_Planet_project/checkpoints/\"+model_name\n",
    "\n",
    "pretrained = True\n",
    "depth = 18\n",
    "test_model = ResNet(depth=depth)\n",
    "model = PlanetModel(model=test_model)\n",
    "model.load_state_dict(torch.load(checkpoint_path)[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49119bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = pl_loggers.CSVLogger(save_dir=\"\", name = \"logs\")\n",
    "\n",
    "max_epochs = 50\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"../IPEO_Planet_project/checkpoints\",\n",
    "    filename=f'ResNet{depth}'+'-{epoch}_'+f'over_{max_epochs}'+'-{val_accuracy:.2f}',\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5373ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=max_epochs, accelerator=\"gpu\", devices=[0], \n",
    "                     logger=csv_logger, callbacks=[checkpoint_callback],\n",
    "                     resume_from_checkpoint=None, check_val_every_n_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f16b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = trainer.predict(model, dataloaders=test_dl) # this can take a little bit of time (like 10-20min depending on your system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg, false_pos = np.zeros((1, 17)), np.zeros((1, 17))\n",
    "y_hat, y = list(map(list, zip(*rs)))\n",
    "overall_accuracy = 0.0\n",
    "hamming_dist = 0.0\n",
    "for i in range(len(y_hat)):\n",
    "    overall_accuracy += overall_acc(y_hat[i], y[i])\n",
    "    hamming_dist += Hamming_distance(y_hat[i], y[i])\n",
    "    false_positive, false_negative = count_false(y_hat[i], y[i])\n",
    "    false_pos += false_positive\n",
    "    false_neg += false_negative\n",
    "overall_accuracy = overall_accuracy/len(y_hat)\n",
    "hamming_dist = hamming_dist/len(y_hat)\n",
    "                                        \n",
    "print(f\"Overall accuracy: {overall_accuracy:.4f}\\nHamming distance: {hamming_dist}\")\n",
    "print(\"False positive (predict 1 instead of 0): \",false_pos, \"\\nFalse negative (predict 0 instead of 1): \",false_neg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c716fb9",
   "metadata": {},
   "source": [
    "#### Make the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imsave, imread\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the logs\n",
    "LOG_PATH = './logs/resnet18_loss_with_weights/metrics.csv'\n",
    "log_df = pd.read_csv(LOG_PATH, sep=';')\n",
    "log_df.index = log_df.epoch\n",
    "log_df.drop(columns=['epoch'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dd2827",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1,fig2,fig3,fig4 = plt.figure(figsize=(15,9)),plt.figure(figsize=(15,9)),plt.figure(figsize=(15,9)),plt.figure(figsize=(15,9))\n",
    "ax1 = fig1.add_subplot(111)\n",
    "ax2 = fig2.add_subplot(111)\n",
    "ax3 = fig3.add_subplot(111)\n",
    "ax4 = fig4.add_subplot(111)\n",
    "axs = [ax1,ax2,ax3,ax4]\n",
    "figs = [fig1,fig2,fig3,fig4]\n",
    "values = [log_df.train_loss, log_df.val_loss, log_df.hamming_dist, log_df.val_accuracy]\n",
    "\n",
    "for i in range(4):\n",
    "  axs[i].set_xlim([0,49])\n",
    "  axs[i].grid(visible=True, which='major', axis='both', linestyle='--', alpha=0.7)\n",
    "  axs[i].plot(log_df.index, values[i])\n",
    "  axs[i].set_xlabel('Epoch', fontsize=15)\n",
    "\n",
    "ax1.set_ylabel('Training loss', fontsize=15), ax1.set_title('Loss on training set\\n', fontsize=20)\n",
    "\n",
    "ax2.set_ylabel('Validation loss', fontsize=15), ax2.set_title('Loss on validation set\\n', fontsize=20)\n",
    "\n",
    "ax3.set_ylabel('Hamming distance', fontsize=15), ax3.set_title('Hamming distance\\n', fontsize=20)\n",
    "\n",
    "ax4.set_ylabel('Validation accuracy', fontsize=15), ax4.set_title('Accuracy of model on validation set\\n', fontsize=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "512cab9a",
   "metadata": {},
   "source": [
    "### Model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"test-epoch=34_over_50-val_accuracy=0.93.ckpt\"\n",
    "checkpoint_path = \"../IPEO_Planet_project/checkpoints/\"+model_name\n",
    "\n",
    "test_model = testModel(max_channels=512) \n",
    "model = PlanetModel(model=test_model)\n",
    "model.load_state_dict(torch.load(checkpoint_path)[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc0d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = pl_loggers.CSVLogger(save_dir=\"\", name = \"logs\")\n",
    "\n",
    "max_epochs = 50\n",
    "\n",
    "\n",
    "ModelCheckpoint(\n",
    "    dirpath=\"../IPEO_Planet_project/checkpoints\",\n",
    "    filename='test-{epoch}_'+ f'over_{max_epochs}'+ '-{val_accuracy:.2f}',\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d637cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=max_epochs, accelerator=\"gpu\", devices=[0], \n",
    "                     logger=csv_logger, callbacks=[checkpoint_callback],\n",
    "                     resume_from_checkpoint=None, check_val_every_n_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dd6d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = trainer.predict(model, dataloaders=test_dl) # this can take a little bit of time (like 10-20min depending on your system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc761dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg, false_pos = np.zeros((1, 17)), np.zeros((1, 17))\n",
    "y_hat, y = list(map(list, zip(*rs)))\n",
    "overall_accuracy = 0.0\n",
    "hamming_dist = 0.0\n",
    "for i in range(len(y_hat)):\n",
    "    overall_accuracy += overall_acc(y_hat[i], y[i])\n",
    "    hamming_dist += Hamming_distance(y_hat[i], y[i])\n",
    "    false_positive, false_negative = count_false(y_hat[i], y[i])\n",
    "    false_pos += false_positive\n",
    "    false_neg += false_negative\n",
    "overall_accuracy = overall_accuracy/len(y_hat)\n",
    "hamming_dist = hamming_dist/len(y_hat)\n",
    "                                        \n",
    "print(f\"Overall accuracy: {overall_accuracy:.4f}\\nHamming distance: {hamming_dist}\")\n",
    "print(\"False positive (predict 1 instead of 0): \",false_pos, \"\\nFalse negative (predict 0 instead of 1): \",false_neg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53d96443",
   "metadata": {},
   "source": [
    "#### Make the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73be6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imsave, imread\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30733aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the logs\n",
    "LOG_PATH = './logs/our_version_loss_with_weights/metrics.csv'\n",
    "log_df = pd.read_csv(LOG_PATH, sep=';')\n",
    "log_df.index = log_df.epoch\n",
    "log_df.drop(columns=['epoch'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48d4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1,fig2,fig3,fig4 = plt.figure(figsize=(15,9)),plt.figure(figsize=(15,9)),plt.figure(figsize=(15,9)),plt.figure(figsize=(15,9))\n",
    "ax1 = fig1.add_subplot(111)\n",
    "ax2 = fig2.add_subplot(111)\n",
    "ax3 = fig3.add_subplot(111)\n",
    "ax4 = fig4.add_subplot(111)\n",
    "axs = [ax1,ax2,ax3,ax4]\n",
    "figs = [fig1,fig2,fig3,fig4]\n",
    "values = [log_df.train_loss, log_df.val_loss, log_df.hamming_dist, log_df.val_accuracy]\n",
    "\n",
    "for i in range(4):\n",
    "  axs[i].set_xlim([0,49])\n",
    "  axs[i].grid(visible=True, which='major', axis='both', linestyle='--', alpha=0.7)\n",
    "  axs[i].plot(log_df.index, values[i])\n",
    "  axs[i].set_xlabel('Epoch', fontsize=15)\n",
    "\n",
    "ax1.set_ylabel('Training loss', fontsize=15), ax1.set_title('Loss on training set\\n', fontsize=20)\n",
    "\n",
    "ax2.set_ylabel('Validation loss', fontsize=15), ax2.set_title('Loss on validation set\\n', fontsize=20)\n",
    "\n",
    "ax3.set_ylabel('Hamming distance', fontsize=15), ax3.set_title('Hamming distance\\n', fontsize=20)\n",
    "\n",
    "ax4.set_ylabel('Validation accuracy', fontsize=15), ax4.set_title('Accuracy of model on validation set\\n', fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b99ff67b40dbeb3d3f51b38f7b4ea8cde4c2bee889619c7ad0240fb7e21d076"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
